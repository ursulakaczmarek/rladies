{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Is this a picture of a puppy or a bagel? Let a convolutional neural network (CNN) tell us\n\nCNNs are computer vision models that look at many pictures (turned into numeric values) and classify what the pictures represent based on those values. CNNs iterate through many pictures and learn the proper classification using some kind of performance measure (i.e. training a model). ","metadata":{}},{"cell_type":"markdown","source":"### step 1: import our libraries\n* numpy and pandas for matrices and text data\n* tensorflow for our neural net","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as img\nimport tensorflow\nfrom tensorflow import keras\nfrom tensorflow.data import AUTOTUNE\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.layers import Input, Rescaling, Conv2D, GlobalAveragePooling2D, Dropout, Dense\nfrom tensorflow.keras.applications import resnet50, mobilenet\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.utils import image_dataset_from_directory, to_categorical\nfrom tensorflow.keras.applications.xception import preprocess_input\nimport cv2\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-21T18:47:39.420280Z","iopub.execute_input":"2023-09-21T18:47:39.420794Z","iopub.status.idle":"2023-09-21T18:47:43.188987Z","shell.execute_reply.started":"2023-09-21T18:47:39.420753Z","shell.execute_reply":"2023-09-21T18:47:43.187962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### step 2: define the parameters of our learning algorithm\n* batch sizes represent the number of samples the model will work through before updating its learning \n* epochs represent the number of whole passes through the training data\n* CNNs use the training data to learn (also split into validation data to grade its performance)\n* Test data is a batch of unseen pictures we run through a trained model\n* the learning rate is a way to optimize how well the model learns during each epoch","metadata":{}},{"cell_type":"code","source":"EPOCHS = 20\nIMGSIZE = 300\nMODEL_NAME = 'cnn_imgsize300'\nOPTIMIZER = 'adam'\nTRAINING_DIR = '../input/bagel-or-puppy/bagel_puppy/training_set/'\nTEST_DIR = '../input/bagel-or-puppy/bagel_puppy/test_set/'","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:47:43.190813Z","iopub.execute_input":"2023-09-21T18:47:43.191410Z","iopub.status.idle":"2023-09-21T18:47:43.196520Z","shell.execute_reply.started":"2023-09-21T18:47:43.191380Z","shell.execute_reply":"2023-09-21T18:47:43.195604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = tensorflow.keras.callbacks.EarlyStopping(\n    patience = 18,\n    min_delta = 0.0005,\n    restore_best_weights = True,\n    )\n\nfilepath = MODEL_NAME+\"_bestweights.hdf5\"\ncheckpoint_callback = ModelCheckpoint(filepath, monitor = 'val_acc', save_best_only = True, mode = 'max')\n\n# learning rate schedule for fine tuning \ndef exponential_lr(epoch, \n                   epochs = EPOCHS,\n                   start_lr = 0.0001, min_lr = 0.0001, max_lr = 0.001,\n                   rampup_epochs = 3, sustain_epochs = 8,\n                   exp_decay = 0.9):\n\n    def lr(epoch, epochs, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs):\n        # linear increase from start to rampup_epochs\n        if epoch < rampup_epochs:\n            lr = ((max_lr - start_lr) /\n                  rampup_epochs * epoch + start_lr)\n        # constant max_lr during sustain_epochs\n        elif epoch < rampup_epochs + sustain_epochs:\n            lr = max_lr\n        # cos decay towards min_lr\n        else:\n            lr = ((max_lr - min_lr) *\n                  exp_decay**(epoch - rampup_epochs - sustain_epochs) +\n                  min_lr)\n            #lr = 0.5 * max_lr * (\n            #1 + np.cos(np.pi * (epoch - rampup_epochs - sustain_epochs) /\n            #    float(epochs - rampup_epochs - sustain_epochs))\n            #)\n        return lr\n    return lr(epoch,\n              epochs,\n              start_lr,\n              min_lr,\n              max_lr,\n              rampup_epochs,\n              sustain_epochs)\n\nlr_callback = tensorflow.keras.callbacks.LearningRateScheduler(exponential_lr, verbose=True)\n\nrng = [i for i in range(EPOCHS)]\ny = [exponential_lr(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:47:43.197876Z","iopub.execute_input":"2023-09-21T18:47:43.198883Z","iopub.status.idle":"2023-09-21T18:47:43.509089Z","shell.execute_reply.started":"2023-09-21T18:47:43.198846Z","shell.execute_reply":"2023-09-21T18:47:43.508010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### step 3: create our training, validation, and test datasets\n* we've loaded a bunch of images of cats and dogs into respective folders\n* the keras package in Python handles the preprocessing for us: sizes all images to the same dimensions, assigns the proper classes","metadata":{}},{"cell_type":"code","source":"training_set = image_dataset_from_directory(TRAINING_DIR, \n                                                 image_size = (IMGSIZE, IMGSIZE),                      \n                                                 batch_size = 9,\n                                                 label_mode = 'categorical',\n                                                 subset = 'training',\n                                                 validation_split = 0.2,\n                                                 seed =  888\n                                                )\n\nvalidation_set = image_dataset_from_directory(TRAINING_DIR, \n                                                 image_size = (IMGSIZE, IMGSIZE), \n                                                 batch_size = 9,\n                                                 label_mode = 'categorical',\n                                                 subset = 'validation',\n                                                 validation_split = 0.2,\n                                                 seed =  888\n                                                  ) # set as validation data\n\ntest_set = image_dataset_from_directory(TEST_DIR, \n                                        image_size = (IMGSIZE, IMGSIZE), \n                                        batch_size = 3\n                                       )\n\nclasses = training_set.class_names","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:47:43.511904Z","iopub.execute_input":"2023-09-21T18:47:43.512340Z","iopub.status.idle":"2023-09-21T18:47:46.588619Z","shell.execute_reply.started":"2023-09-21T18:47:43.512303Z","shell.execute_reply":"2023-09-21T18:47:46.587412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### what our training data looks like","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (10, 10))\nfor images, labels in training_set.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype('uint8'))\n    plt.title(classes[np.argmax(labels[i])])\n    plt.axis('off')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:47:46.590486Z","iopub.execute_input":"2023-09-21T18:47:46.591189Z","iopub.status.idle":"2023-09-21T18:47:48.327183Z","shell.execute_reply.started":"2023-09-21T18:47:46.591135Z","shell.execute_reply":"2023-09-21T18:47:48.321118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### step 4: building a model using transfer learning\ntransfer learning involves using a base model (in this case the xception model) that was developed for another task as our starting point for this task. Xception is a model that was trained to recognize about 1000 different objects, not just bagels and dogs. ","metadata":{}},{"cell_type":"code","source":"# the RGB channel values are in the [0, 255] range-not ideal for a neural network\n# we want to make our input values small\n# standardize values to be in the [0, 1] range by using tf.keras.layers.Rescaling:\n# two possible ways: mapping\n# training_set = training_set.map(lambda x, y: (normalization_layer(x), y))\n# image_batch, labels_batch = next(iter(training_set))\n# first_image = image_batch[0]\n# Notice the pixel values are now in `[0,1]`.\n# print(np.min(first_image), np.max(first_image))\n\n# or include the layer inside the model definition to simplify deployment","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:47:48.328304Z","iopub.execute_input":"2023-09-21T18:47:48.328674Z","iopub.status.idle":"2023-09-21T18:47:48.334302Z","shell.execute_reply.started":"2023-09-21T18:47:48.328642Z","shell.execute_reply":"2023-09-21T18:47:48.333420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# performance enhancers:\n# keep the images in memory after they're loaded off disk during the first epoch with cache()\n# overlap data preprocessing and model execution while training\ntraining_set = training_set.cache().prefetch(buffer_size = AUTOTUNE)\nvalidation_set = validation_set.cache().prefetch(buffer_size = AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:47:48.336226Z","iopub.execute_input":"2023-09-21T18:47:48.337310Z","iopub.status.idle":"2023-09-21T18:47:48.360765Z","shell.execute_reply.started":"2023-09-21T18:47:48.337275Z","shell.execute_reply":"2023-09-21T18:47:48.359740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pre-trained base (this is transfer learning)\nxnet = keras.applications.xception.Xception(\n    weights = 'imagenet',\n    include_top = False ,\n    input_shape = (IMGSIZE, IMGSIZE, 3)\n)\nxnet.trainable = False\n\n# base & head \nmodel = keras.Sequential([\n    xnet,\n    layers.Rescaling(1./255),\n    layers.Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', input_shape = (IMGSIZE, IMGSIZE, 3)),  \n    layers.GlobalAveragePooling2D(),\n    layers.Dense(512, activation = 'relu'),\n    layers.Dropout(0.2),\n    layers.Dense(512, activation = 'relu'),\n    layers.Dense(256, activation = 'relu'),\n    layers.Dense(2, activation = 'softmax')\n])\n\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:47:48.362273Z","iopub.execute_input":"2023-09-21T18:47:48.363110Z","iopub.status.idle":"2023-09-21T18:47:50.683493Z","shell.execute_reply.started":"2023-09-21T18:47:48.363076Z","shell.execute_reply":"2023-09-21T18:47:50.682637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### step 5: train and evaluate the model\nwe will evaulate performance by looking at the loss function (how well the model's learning went) and the classification accuracy on the validation set\n\nwe will also explore a popular method for increasing the performance of CNNs: data augmentation","metadata":{}},{"cell_type":"code","source":"history = model.fit(training_set, \n                    epochs = EPOCHS, \n                    validation_data = validation_set, \n                    callbacks = [early_stopping, checkpoint_callback, lr_callback]\n                   )","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:47:50.684963Z","iopub.execute_input":"2023-09-21T18:47:50.685325Z","iopub.status.idle":"2023-09-21T18:48:18.059772Z","shell.execute_reply.started":"2023-09-21T18:47:50.685291Z","shell.execute_reply":"2023-09-21T18:48:18.058747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_training_curves(training, validation, title, subplot):\n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize = (10,10), facecolor = '#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])\n\ndisplay_training_curves(\n    history.history['loss'],\n    history.history['val_loss'],\n    'loss',\n    211,\n)\n\ndisplay_training_curves(\n    history.history['accuracy'],\n    history.history['val_accuracy'],\n    'accuracy',\n    212,\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:48:18.065785Z","iopub.execute_input":"2023-09-21T18:48:18.066125Z","iopub.status.idle":"2023-09-21T18:48:18.896979Z","shell.execute_reply.started":"2023-09-21T18:48:18.066094Z","shell.execute_reply":"2023-09-21T18:48:18.892948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### see that big gap between our training set accuracy and validation set accuracy? our model is overfitting\n\nwhen there are a small number of training examples, the model sometimes learns from unwanted details (noise) in those training examples, to the extent it negatively affects the performance of the model on the test data.\n\nlet's see if augmentation, i.e. adding additional training data by randomly transforming the images we already have in our training set, helps improve performance","metadata":{}},{"cell_type":"code","source":"# define transformations\ndata_augmentation = keras.Sequential(\n  [layers.RandomZoom(0.2),\n   layers.RandomFlip(input_shape = (IMGSIZE, IMGSIZE, 3)),\n   layers.RandomRotation(0.5, fill_mode = 'constant', fill_value = 1),\n  ]\n)\n\ntraining_set_aug = training_set.map(lambda x, y: (data_augmentation(x), y))","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:48:18.898757Z","iopub.execute_input":"2023-09-21T18:48:18.899183Z","iopub.status.idle":"2023-09-21T18:48:19.342622Z","shell.execute_reply.started":"2023-09-21T18:48:18.899143Z","shell.execute_reply":"2023-09-21T18:48:19.341489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize transformations\nplt.figure(figsize = (10, 10))\nfor images, _ in training_set_aug.take(7):\n    for i in range(9):\n        augmented_images = data_augmentation(images)\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(augmented_images[0].numpy().astype('uint8'))\n        plt.axis('off')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:48:19.344463Z","iopub.execute_input":"2023-09-21T18:48:19.344873Z","iopub.status.idle":"2023-09-21T18:48:24.460079Z","shell.execute_reply.started":"2023-09-21T18:48:19.344836Z","shell.execute_reply":"2023-09-21T18:48:24.458866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(training_set_aug, \n                    epochs = EPOCHS, \n                    validation_data = validation_set, \n                    callbacks = [early_stopping, checkpoint_callback, lr_callback]\n                   )","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:48:24.461895Z","iopub.execute_input":"2023-09-21T18:48:24.462353Z","iopub.status.idle":"2023-09-21T18:49:04.789999Z","shell.execute_reply.started":"2023-09-21T18:48:24.462317Z","shell.execute_reply":"2023-09-21T18:49:04.788902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_training_curves(\n    history.history['loss'],\n    history.history['val_loss'],\n    'loss',\n    211,\n)\n\ndisplay_training_curves(\n    history.history['accuracy'],\n    history.history['val_accuracy'],\n    'accuracy',\n    212,\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:49:04.794545Z","iopub.execute_input":"2023-09-21T18:49:04.797175Z","iopub.status.idle":"2023-09-21T18:49:05.807804Z","shell.execute_reply.started":"2023-09-21T18:49:04.797135Z","shell.execute_reply":"2023-09-21T18:49:05.806669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### step 6: running test data through our trained model to see how well it can classify new images of cats and dogs\n","metadata":{}},{"cell_type":"code","source":"# save the model using the weights that yielded the highest accuracy\nmodel.save(filepath)\nmodel_best = load_model(filepath, compile = True)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:49:05.809386Z","iopub.execute_input":"2023-09-21T18:49:05.809909Z","iopub.status.idle":"2023-09-21T18:49:08.594827Z","shell.execute_reply.started":"2023-09-21T18:49:05.809869Z","shell.execute_reply":"2023-09-21T18:49:08.593817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model_best.predict(test_set, \n                                 verbose = 0,\n                                 callbacks = None)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:58:13.027618Z","iopub.execute_input":"2023-09-21T18:58:13.028040Z","iopub.status.idle":"2023-09-21T18:58:13.428578Z","shell.execute_reply.started":"2023-09-21T18:58:13.028008Z","shell.execute_reply":"2023-09-21T18:58:13.427547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_class_indices = np.argmax(predictions, axis = -1)\npredicted_class_confidence = 100*np.max(predictions, axis = -1)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:58:40.112673Z","iopub.execute_input":"2023-09-21T18:58:40.113081Z","iopub.status.idle":"2023-09-21T18:58:40.119516Z","shell.execute_reply.started":"2023-09-21T18:58:40.113053Z","shell.execute_reply":"2023-09-21T18:58:40.118052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = [0, 1]\nnames = (test_set.class_names)\nlabels = dict(zip(labels, names))\npredicted_names = [names[k] for k in predicted_class_indices]","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:58:40.738463Z","iopub.execute_input":"2023-09-21T18:58:40.738842Z","iopub.status.idle":"2023-09-21T18:58:40.746260Z","shell.execute_reply.started":"2023-09-21T18:58:40.738811Z","shell.execute_reply":"2023-09-21T18:58:40.743706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames = [os.path.join(root, name)\n             for root, dirs, files in os.walk(TEST_DIR)\n                 for name in files\n                 if name.endswith('.jpg')]\nfilenames.sort()\n\ntrue_labels = [os.path.split(os.path.dirname(file))[-1] for file in filenames]\n\ntest_df = pd.DataFrame({\n    'filename': filenames,\n    'true_name': true_labels,\n    'predicted_name': predicted_names,\n    '% confidence ': predicted_class_confidence\n})\npd.set_option('display.max_colwidth', None)\ntest_df.head(20)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:58:42.921489Z","iopub.execute_input":"2023-09-21T18:58:42.921863Z","iopub.status.idle":"2023-09-21T18:58:42.946023Z","shell.execute_reply.started":"2023-09-21T18:58:42.921831Z","shell.execute_reply":"2023-09-21T18:58:42.945142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_correct = test_df.query('true_name == predicted_name').sample(n = 6, replace = False)\nplt.subplots(2, 3, figsize = (18, 8))\n\nfor i in range(len(sample_correct)):\n    plt.subplot(2, 3, i + 1)\n    plt.axis('Off')\n    image = img.imread(sample_correct.iloc[i][0])\n    plt.imshow(image)\n    plt.title(f'label: {sample_correct.iloc[i][2]}\\n confidence: {sample_correct.iloc[i][3]:.3f}%', fontsize = 12);","metadata":{"execution":{"iopub.status.busy":"2023-09-21T19:02:27.572661Z","iopub.execute_input":"2023-09-21T19:02:27.573145Z","iopub.status.idle":"2023-09-21T19:02:32.451080Z","shell.execute_reply.started":"2023-09-21T19:02:27.573108Z","shell.execute_reply":"2023-09-21T19:02:32.450069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_incorrect = test_df.query('true_name != predicted_name').sample(n = 6, replace = False)\nplt.subplots(2, 3, figsize = (12, 12))\n\nfor i in range(len(sample_incorrect)):\n    plt.subplot(2, 3, i + 1)\n    plt.axis('Off')\n    image = img.imread(sample_incorrect.iloc[i][0])\n    plt.imshow(image)\n    plt.title(f'label: {sample_incorrect.iloc[i][2]}\\n confidence: {sample_incorrect.iloc[i][3]:.3f}%', fontsize = 16);","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:59:00.684306Z","iopub.execute_input":"2023-09-21T18:59:00.684988Z","iopub.status.idle":"2023-09-21T18:59:01.642184Z","shell.execute_reply.started":"2023-09-21T18:59:00.684954Z","shell.execute_reply":"2023-09-21T18:59:01.641183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nfilenames = [os.path.join(root, name)\n             for root, dirs, files in os.walk(TEST_DIR)\n                 for name in files\n                 if name.endswith('.jpg')]\n\nimport PIL.Image\nPIL.Image.open(str(filenames[0]))\n'''\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}